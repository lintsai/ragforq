# Q槽路徑設置
Q_DRIVE_PATH="/mnt/winshare/MIC/"
DISPLAY_DRIVE_NAME="Q:/"

# 向量數據庫設置
VECTOR_DB_PATH="/app/db"
LOGS_DIR="/app/logs"
BACKUPS_DIR="/app/backups"

# 文件類型設置
SUPPORTED_FILE_TYPES=".pdf,.docx,.doc,.xlsx,.xls,.txt,.md,.pptx,.ppt,.csv,.vsdx,.vsd"

# 應用設置
APP_HOST=192.168.100.121
APP_PORT=8000
STREAMLIT_PORT=8501

# 其他設置
LOG_LEVEL="INFO"
MAX_TOKENS_CHUNK=500
CHUNK_OVERLAP=100
SIMILARITY_TOP_K=10

# 索引效能優化設置（優化後）
MAX_WORKERS=0
EMBEDDING_BATCH_SIZE=32
FILE_BATCH_SIZE=10
MAX_FILE_SIZE_MB=50

# 編碼處理優化
AUTO_ENCODING_DETECTION=true
USE_CHARDET=true
CLEAN_GARBLED_TEXT=true

# 動態RAG優化設置
DYNAMIC_MAX_SCAN_FILES=5000
DYNAMIC_SCAN_DEPTH=8
DYNAMIC_CACHE_DURATION=300

# === Ollama 設置 ===
# 生產環境中的 Ollama 服務
OLLAMA_HOST="http://localhost:11434"

# Ollama 超時設定（秒）- 優化後
OLLAMA_REQUEST_TIMEOUT=300              # 一般請求超時（增加到5分鐘）
OLLAMA_EMBEDDING_TIMEOUT=180            # 嵌入向量生成超時（增加到3分鐘）
OLLAMA_QUERY_OPTIMIZATION_TIMEOUT=90    # 查詢優化超時
OLLAMA_ANSWER_GENERATION_TIMEOUT=300    # 回答生成超時（增加到5分鐘）
OLLAMA_RELEVANCE_TIMEOUT=120            # 相關性分析超時（增加到2分鐘）
OLLAMA_CONNECTION_TIMEOUT=60            # 連接超時（增加到1分鐘）

# 重試機制設定
OLLAMA_MAX_RETRIES=3                    # 最大重試次數
OLLAMA_RETRY_DELAY=5                    # 重試延遲（秒）

# === Hugging Face 設置 ===
HF_MODEL_CACHE_DIR="/app/models/cache"
HF_USE_GPU="true"
HF_TOKEN=""

# 推理引擎配置（通過前端設置流程選擇，以下僅為默認值）
VLLM_GPU_MEMORY_UTILIZATION="0.9"
VLLM_MAX_MODEL_LEN="4096"
VLLM_TENSOR_PARALLEL_SIZE="1"

# PyTorch 設置
TORCH_DEVICE="auto"
TORCH_DTYPE="float16"

# 環境設置
ENVIRONMENT="production"

# 自訂的管理員安全密碼
ADMIN_TOKEN=ragadmin123