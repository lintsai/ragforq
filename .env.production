# Q槽路徑設置
Q_DRIVE_PATH="/mnt/winshare/MIC/"
DISPLAY_DRIVE_NAME="Q:/"

# 向量數據庫設置
VECTOR_DB_PATH="/app/db"
LOGS_DIR="/app/logs"
BACKUPS_DIR="/app/backups"

# 文件類型設置
SUPPORTED_FILE_TYPES=".pdf,.docx,.doc,.xlsx,.xls,.txt,.md,.pptx,.ppt,.csv,.vsdx,.vsd"

# 應用設置
APP_HOST=192.168.100.121
APP_PORT=8000
STREAMLIT_PORT=8501

# 其他設置
LOG_LEVEL="INFO"
MAX_TOKENS_CHUNK=500
CHUNK_OVERLAP=100
SIMILARITY_TOP_K=10

# 索引效能優化設置
MAX_WORKERS=0
EMBEDDING_BATCH_SIZE=64
FILE_BATCH_SIZE=20

# === Ollama 設置 ===
# 生產環境中的 Ollama 服務
OLLAMA_HOST="http://localhost:11434"

# Ollama 超時設定（秒）
OLLAMA_REQUEST_TIMEOUT=180              # 一般請求超時
OLLAMA_EMBEDDING_TIMEOUT=120            # 嵌入向量生成超時
OLLAMA_QUERY_OPTIMIZATION_TIMEOUT=60    # 查詢優化超時
OLLAMA_ANSWER_GENERATION_TIMEOUT=180    # 回答生成超時
OLLAMA_RELEVANCE_TIMEOUT=90             # 相關性分析超時
OLLAMA_CONNECTION_TIMEOUT=30            # 連接超時

# === Hugging Face 設置 ===
HF_MODEL_CACHE_DIR="/app/models/cache"
HF_USE_GPU="true"
HF_TOKEN=""

# 推理引擎配置（通過前端設置流程選擇，以下僅為默認值）
VLLM_GPU_MEMORY_UTILIZATION="0.9"
VLLM_MAX_MODEL_LEN="4096"
VLLM_TENSOR_PARALLEL_SIZE="1"

# PyTorch 設置
TORCH_DEVICE="auto"
TORCH_DTYPE="float16"

# 環境設置
ENVIRONMENT="production"

# 自訂的管理員安全密碼
ADMIN_TOKEN=ragadmin123