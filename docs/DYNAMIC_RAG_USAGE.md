# Dynamic RAG 使用指南

## 概述

Dynamic RAG（動態檢索增強生成）是一種新的RAG架構，無需預先建立向量資料庫，而是在查詢時即時檢索和處理相關文件。

## 主要優勢

### 1. 即時性
- **無需等待索引**：不需要預先建立向量資料庫
- **實時更新**：文件變更立即生效
- **快速部署**：系統可以立即使用

### 2. 資源效率
- **節省存儲空間**：不需要存儲大型向量資料庫
- **降低內存使用**：按需加載和處理文件
- **減少維護成本**：無需管理索引更新

### 3. 靈活性
- **動態文件檢索**：智能選擇最相關的文件
- **適應性強**：自動適應不同類型的查詢
- **擴展性好**：易於處理大規模文件庫

## 使用方法

### 1. Web界面使用

#### 啟用Dynamic RAG
1. 打開前端界面：`http://localhost:8501`
2. 在左側邊欄的「設置」區域
3. 選擇「RAG模式」為「Dynamic RAG」
4. 配置必要的模型參數

#### 模型配置
- **語言模型**：選擇用於回答生成的Ollama模型（如 `phi3:mini`）
- **嵌入模型**：選擇用於文本向量化的模型（如 `nomic-embed-text`）

#### 開始問答
- 在聊天框中輸入問題
- 系統會自動：
  1. 智能檢索相關文件
  2. 即時解析文件內容
  3. 向量化查詢和文檔
  4. 計算相似度並生成回答

### 2. API使用

#### 基本請求
```bash
curl -X POST "http://localhost:8000/ask" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "什麼是ITPortal？",
    "use_dynamic_rag": true,
    "selected_model": "phi3:mini",
    "ollama_embedding_model": "nomic-embed-text",
    "language": "繁體中文"
  }'
```

#### 請求參數說明
- `question`: 用戶問題
- `use_dynamic_rag`: 設為 `true` 啟用Dynamic RAG
- `selected_model`: Ollama語言模型名稱
- `ollama_embedding_model`: Ollama嵌入模型名稱
- `language`: 回答語言
- `include_sources`: 是否包含來源信息（可選）
- `use_query_rewrite`: 是否使用查詢優化（可選）

### 3. 程式化使用

```python
from rag_engine.dynamic_rag_engine import DynamicRAGEngine

# 創建Dynamic RAG引擎
engine = DynamicRAGEngine(
    ollama_model="phi3:mini",
    ollama_embedding_model="nomic-embed-text",
    language="繁體中文"
)

# 回答問題
answer = engine.answer_question("什麼是ITPortal？")
print(answer)

# 獲取帶來源的回答
answer, sources, documents = engine.get_answer_with_sources("公司政策是什麼？")
print(f"回答: {answer}")
print(f"來源: {sources}")
```

## 工作原理

### 1. 智能文件檢索
- **關鍵詞匹配**：基於問題關鍵詞匹配文件名和路徑
- **語義分析**：分析文件路徑的語義含義
- **優先級排序**：根據文件類型、大小、修改時間等因素排序
- **動態篩選**：智能選擇最相關的文件子集

### 2. 動態內容處理
- **並行解析**：使用多線程並行處理多個文件
- **智能分段**：將文檔內容分割為適當大小的段落
- **內容緩存**：緩存已處理的文件內容以提高效率
- **錯誤處理**：優雅處理文件讀取和解析錯誤

### 3. 即時向量化
- **查詢向量化**：將用戶問題轉換為向量表示
- **文檔向量化**：批量處理文檔段落的向量化
- **相似度計算**：使用餘弦相似度計算相關性
- **結果排序**：按相似度排序並選擇最佳匹配

### 4. 回答生成
- **上下文構建**：將最相關的文檔段落組合為上下文
- **提示工程**：使用優化的提示模板生成回答
- **語言一致性**：確保回答語言與用戶選擇一致
- **來源標註**：提供清晰的文檔來源信息

## 性能優化

### 1. 緩存策略
- **查詢緩存**：緩存常見查詢的向量表示
- **內容緩存**：緩存已解析的文件內容
- **文件緩存**：緩存文件元數據以加速檢索

### 2. 並行處理
- **文件並行**：同時處理多個文件
- **向量並行**：批量進行向量化操作
- **資源管理**：動態調整並行度以優化資源使用

### 3. 智能預篩選
- **文件過濾**：提前過濾不相關的文件
- **大小限制**：限制處理的文件數量和大小
- **類型優先**：優先處理特定類型的文件

## 適用場景

### 1. 理想場景
- **文件經常變更**：需要實時反映最新內容
- **存儲空間有限**：無法存儲大型向量資料庫
- **快速部署**：需要立即使用系統
- **小到中型文件庫**：文件數量在合理範圍內

### 2. 不適用場景
- **超大型文件庫**：文件數量過多會影響檢索速度
- **高頻查詢**：大量並發查詢可能造成性能瓶頸
- **穩定文件庫**：文件很少變更的情況下傳統RAG更高效

## 與傳統RAG的對比

| 特性 | 傳統RAG | Dynamic RAG |
|------|---------|-------------|
| 初始化時間 | 長（需建立索引） | 短（立即可用） |
| 存儲需求 | 高（向量資料庫） | 低（僅文件） |
| 查詢延遲 | 低（預建索引） | 中等（即時處理） |
| 實時性 | 低（需重建索引） | 高（立即生效） |
| 維護成本 | 高（索引管理） | 低（無需維護） |
| 擴展性 | 中等 | 高 |
| 適用規模 | 大型 | 小到中型 |

## 故障排除

### 1. 常見問題

#### 查詢速度慢
- **原因**：文件數量過多或文件過大
- **解決**：調整檢索參數，限制文件數量

#### 找不到相關文件
- **原因**：關鍵詞匹配不準確
- **解決**：使用更具體的關鍵詞，或調整檢索策略

#### 向量化失敗
- **原因**：Ollama模型不可用
- **解決**：檢查Ollama服務狀態，確認模型已下載

### 2. 性能調優

#### 調整並行度
```python
# 在 DynamicContentProcessor 中調整
max_workers = 4  # 根據系統資源調整
```

#### 優化緩存設置
```python
# 調整緩存時間
cache_duration = 600  # 10分鐘
```

#### 限制文件處理
```python
# 限制最大文件數
max_files = 10
```

## 最佳實踐

### 1. 模型選擇
- **語言模型**：選擇適合目標語言的模型
- **嵌入模型**：選擇高質量的嵌入模型
- **資源平衡**：根據硬體資源選擇合適大小的模型

### 2. 查詢優化
- **具體問題**：使用具體、明確的問題
- **關鍵詞豐富**：包含相關的專業術語
- **上下文清晰**：提供足夠的背景信息

### 3. 系統配置
- **文件組織**：合理組織文件目錄結構
- **命名規範**：使用有意義的文件名
- **定期清理**：清理無用或過時的文件

## 未來發展

### 1. 計劃改進
- **更智能的文件檢索**：使用機器學習改進檢索策略
- **更好的緩存機制**：實現更高效的多級緩存
- **自適應優化**：根據使用模式自動調整參數

### 2. 擴展功能
- **多模態支持**：支援圖片、音頻等多媒體文件
- **協作功能**：支援多用戶協作和共享
- **分析報告**：提供使用統計和性能分析

## 結論

Dynamic RAG 提供了一種靈活、高效的文檔問答解決方案，特別適合需要實時性和靈活性的應用場景。雖然在某些方面不如傳統RAG，但其獨特的優勢使其成為特定場景下的理想選擇。

通過合理的配置和優化，Dynamic RAG 可以為用戶提供快速、準確的文檔問答服務，同時大大降低系統的部署和維護成本。