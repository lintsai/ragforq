# Q槽路徑設置
Q_DRIVE_PATH="D:/source/ragforq/test_files/"
DISPLAY_DRIVE_NAME="D:/source/ragforq/test_files/"

# 向量數據庫設置
VECTOR_DB_PATH="./vector_db"
LOGS_DIR="./logs"
BACKUPS_DIR="./backups"

# 文件類型設置
SUPPORTED_FILE_TYPES=".pdf,.docx,.doc,.xlsx,.xls,.txt,.md,.pptx,.ppt,.csv,.vsdx,.vsd"

# 應用設置
APP_HOST=127.0.0.1
APP_PORT=8000
STREAMLIT_PORT=8501

# 其他設置
LOG_LEVEL="INFO"
MAX_TOKENS_CHUNK=500
CHUNK_OVERLAP=100
SIMILARITY_TOP_K=10

# 索引效能優化設置（針對大量文件優化）
MAX_WORKERS=1
EMBEDDING_BATCH_SIZE=4
FILE_BATCH_SIZE=3
MAX_FILE_SIZE_MB=20

# CUDA 記憶體管理設置 - 修復記憶體碎片化問題
PYTORCH_CUDA_ALLOC_CONF="max_split_size_mb:512,expandable_segments:False,garbage_collection_threshold:0.6"
CUDA_LAUNCH_BLOCKING=0
TORCH_CUDA_EMPTY_CACHE_FREQUENCY=10
CUDA_VISIBLE_DEVICES="0,1"

# 模型加載安全設置
MODEL_LOAD_MAX_RETRIES=2
MODEL_LOAD_RETRY_DELAY=5
FORCE_MODEL_RELOAD=false

# 智能回退模型配置（可根據需要自定義）
FALLBACK_MEDIUM_MODEL="microsoft/DialoGPT-medium"
FALLBACK_SMALL_MODEL="microsoft/DialoGPT-small"  
FALLBACK_TINY_MODEL="distilgpt2"

# 編碼處理優化
AUTO_ENCODING_DETECTION=true
USE_CHARDET=true
CLEAN_GARBLED_TEXT=true

# 動態RAG優化設置（開發環境）
DYNAMIC_MAX_SCAN_FILES=1000
DYNAMIC_SCAN_DEPTH=5
DYNAMIC_CACHE_DURATION=300
DYNAMIC_FOLDER_SELECTION=true

# 文件夾瀏覽優化設置（開發環境）
FOLDER_SCAN_MAX_FILES=100               # 開發環境可以掃描更多文件
FOLDER_SCAN_MAX_DEPTH=2                 # 開發環境可以掃描更深
FOLDER_SCAN_TIMEOUT=10                  # 開發環境允許更長超時

# === Ollama 設置 ===
OLLAMA_HOST="http://localhost:11434"

# Ollama 超時設定（秒）- 優化後（開發環境）
OLLAMA_REQUEST_TIMEOUT=120              # 一般請求超時（開發環境較短）
OLLAMA_EMBEDDING_TIMEOUT=60             # 嵌入向量生成超時
OLLAMA_QUERY_OPTIMIZATION_TIMEOUT=60    # 查詢優化超時
OLLAMA_ANSWER_GENERATION_TIMEOUT=120    # 回答生成超時
OLLAMA_RELEVANCE_TIMEOUT=60             # 相關性分析超時
OLLAMA_CONNECTION_TIMEOUT=30            # 連接超時

# 重試機制設定
OLLAMA_MAX_RETRIES=3                    # 最大重試次數
OLLAMA_RETRY_DELAY=3                    # 重試延遲（秒）

# === Hugging Face 設置 ===
HF_MODEL_CACHE_DIR="./models/cache"
HF_USE_GPU="true"
HF_TOKEN=""

# 模型設置 - 根據 GPU 記憶體自動選擇
DEFAULT_LLM_MODEL="Qwen/Qwen2-0.5B-Instruct"
DEFAULT_EMBEDDING_MODEL="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"

# 推理引擎配置（通過前端設置流程選擇，以下僅為默認值）
VLLM_GPU_MEMORY_UTILIZATION="0.7"
VLLM_MAX_MODEL_LEN="4096"
VLLM_TENSOR_PARALLEL_SIZE="2"

# PyTorch 設置 - 優化記憶體管理
TORCH_DEVICE="auto"
TORCH_DTYPE="bfloat16"

# 環境設置
ENVIRONMENT="development"

# 自訂的管理員安全密碼
ADMIN_TOKEN=ragadmin123
