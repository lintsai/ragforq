#!/usr/bin/env python
"""
ç´¢å¼•ç›£æ§è…³æœ¬ - å¯¦æ™‚ç›£æ§ç´¢å¼•é€²åº¦å’Œç³»çµ±ç‹€æ…‹
"""

import os
import sys
import time
import json
import argparse
from pathlib import Path
from datetime import datetime
import pytz
from typing import Optional

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°è·¯å¾‘
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.vector_db_manager import VectorDBManager


def clear_screen():
    """æ¸…å±"""
    os.system('cls' if os.name == 'nt' else 'clear')

def get_file_size_str(size_bytes):
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    if size_bytes == 0:
        return "0B"
    size_names = ["B", "KB", "MB", "GB", "TB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024.0
        i += 1
    return f"{size_bytes:.1f}{size_names[i]}"

def get_indexing_status(model_folder_name: Optional[str] = None):
    """
    ç²å–ç´¢å¼•ç‹€æ…‹ã€‚
    å¦‚æœæä¾›äº† model_folder_nameï¼Œå‰‡åªç²å–è©²æ¨¡å‹çš„ç‹€æ…‹ã€‚
    å¦å‰‡ï¼Œæƒææ‰€æœ‰æ¨¡å‹ä»¥æŸ¥æ‰¾æ­£åœ¨è¨“ç·´çš„æ¨¡å‹ã€‚
    """
    db_manager = VectorDBManager()
    
    training_model_path = None
    display_name = None

    if model_folder_name:
        # æª¢æŸ¥ç‰¹å®šæ¨¡å‹
        model_path = db_manager.base_path / model_folder_name
        if model_path.exists():
            model_info = db_manager.get_model_info(model_path)
            display_name = db_manager._get_display_name(model_folder_name, model_info)
            # åªæœ‰ç•¶å®ƒçœŸçš„åœ¨è¨“ç·´æ™‚ï¼Œæ‰å°‡å…¶è¦–ç‚ºç›®æ¨™
            if db_manager.is_training(model_path):
                 training_model_path = model_path
    else:
        # å…¨åŸŸæƒæ
        models = db_manager.list_available_models()
        for model in models:
            if model['is_training']:
                training_model_path = Path(model['folder_path'])
                display_name = model['display_name']
                break

    status = {
        'training_model_name': display_name if training_model_path else (display_name if model_folder_name else None),
        'is_training': training_model_path is not None,
        'progress_file_exists': False,
        'progress': {},
        'indexed_files_count': 0,
        'vector_db_size': 0,
        'log_file_size': 0,
        'last_log_lines': []
    }
    
    # ç‹€æ…‹å ±å‘Šçš„ç›®æ¨™è·¯å¾‘ï¼ˆç„¡è«–æ˜¯å¦åœ¨è¨“ç·´ä¸­ï¼‰
    status_target_path = db_manager.base_path / model_folder_name if model_folder_name else training_model_path

    if not status_target_path:
        return status

    # æª¢æŸ¥é€²åº¦æ–‡ä»¶
    progress_file = status_target_path / "indexing_progress.json"
    if progress_file.exists():
        status['progress_file_exists'] = True
        try:
            with open(progress_file, 'r', encoding='utf-8') as f:
                status['progress'] = json.load(f)
        except Exception as e:
            status['progress'] = {'error': str(e)}
    
    # æª¢æŸ¥å·²ç´¢å¼•æ–‡ä»¶æ•¸é‡
    indexed_files_path = status_target_path / "indexed_files.pkl"
    if indexed_files_path.exists():
        try:
            import pickle
            with open(indexed_files_path, 'rb') as f:
                indexed_files = pickle.load(f)
                status['indexed_files_count'] = len(indexed_files)
        except Exception:
            status['indexed_files_count'] = 0
    
    # æª¢æŸ¥å‘é‡æ•¸æ“šåº«å¤§å°
    vector_files = [
        status_target_path / "index.faiss",
        status_target_path / "index.pkl"
    ]
    total_size = 0
    for file_path in vector_files:
        if file_path.exists():
            total_size += file_path.stat().st_size
    status['vector_db_size'] = total_size
    
    # æª¢æŸ¥æ—¥èªŒæ–‡ä»¶
    log_file = Path(f"logs/{status_target_path.name}.log")
    if log_file.exists():
        status['log_file_size'] = log_file.stat().st_size
        try:
            with open(log_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                status['last_log_lines'] = [line.strip() for line in lines[-10:]]
        except Exception:
            status['last_log_lines'] = ["ç„¡æ³•è®€å–æ—¥èªŒæ–‡ä»¶"]
    
    return status

def get_system_status():
    """ç²å–ç³»çµ±ç‹€æ…‹"""
    status = {
        'memory_percent': 0,
        'disk_percent': 0,
        'q_drive_accessible': False,
        'ollama_running': False
    }
    
    try:
        import psutil
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        status['memory_percent'] = memory.percent
        status['disk_percent'] = disk.percent
    except ImportError:
        pass
    
    # æª¢æŸ¥ Q æ§½
    try:
        from config.config import Q_DRIVE_PATH
        if os.path.exists(Q_DRIVE_PATH):
            os.listdir(Q_DRIVE_PATH)  # å˜—è©¦åˆ—å‡ºå…§å®¹
            status['q_drive_accessible'] = True
    except Exception:
        pass
    
    # æª¢æŸ¥ Ollama
    try:
        import requests
        from config.config import OLLAMA_HOST
        response = requests.get(f"{OLLAMA_HOST}/api/tags", timeout=3)
        status['ollama_running'] = response.status_code == 200
    except Exception:
        pass
    
    return status

def display_status(model_folder_name: Optional[str] = None):
    """é¡¯ç¤ºç‹€æ…‹ä¿¡æ¯"""
    clear_screen()
    
    print("=" * 80)
    print(f"ç´¢å¼•ç›£æ§é¢æ¿ - {datetime.now(pytz.timezone('Asia/Taipei')).strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)
    
    # ç²å–ç‹€æ…‹
    indexing_status = get_indexing_status(model_folder_name)
    system_status = get_system_status()
    
    # é¡¯ç¤ºç´¢å¼•ç‹€æ…‹
    print("\nğŸ“Š ç´¢å¼•ç‹€æ…‹:")
    print("-" * 40)
    
    training_model_name = indexing_status.get('training_model_name')
    if training_model_name:
        # èª¿æ•´é¡¯ç¤ºæ–‡å­—ï¼šä½¿ç”¨è€…åé¥‹ã€Œå·²é¸æ“‡ï¼ˆæœªåœ¨è¨“ç·´ï¼‰ã€èªæ„ä¸æ¸…ï¼Œæ”¹ç‚ºæ›´ç›´ç™½
        status_text = "æ­£åœ¨è¨“ç·´ä¸­" if indexing_status.get('is_training') else "å·²é¸æ“‡ï¼ˆå¯ç”¨ï¼‰"
        print(f"ğŸ¯ ç•¶å‰ç›£æ§æ¨¡å‹: {training_model_name} ({status_text})")
    else:
        print("ğŸ’¤ æœªæŒ‡å®šç›£æ§æ¨¡å‹æˆ–ç„¡æ¨¡å‹æ­£åœ¨è¨“ç·´")

    if indexing_status['progress_file_exists']:
        progress = indexing_status['progress']
        if 'error' in progress:

            print(f"âŒ é€²åº¦æ–‡ä»¶éŒ¯èª¤: {progress['error']}")
        else:
            in_progress = progress.get('in_progress', False)
            completed_batches = progress.get('completed_batches', 0)
            total_batches = progress.get('total_batches', 0)
            pending_files = len(progress.get('pending_files', []))
            
            status_icon = "ğŸ”„" if in_progress else "âœ…"
            status_text = "é€²è¡Œä¸­" if in_progress else "å·²å®Œæˆ"
            
            print(f"{status_icon} ç‹€æ…‹: {status_text}")
            print(f"ğŸ“¦ æ‰¹æ¬¡é€²åº¦: {completed_batches}/{total_batches}")
            if total_batches > 0:
                progress_percent = (completed_batches / total_batches) * 100
                print(f"ğŸ“ˆ å®Œæˆåº¦: {progress_percent:.1f}%")
            print(f"ğŸ“„ å¾…è™•ç†æ–‡ä»¶: {pending_files:,}")
    else:
        print("â“ æœªæ‰¾åˆ°é€²åº¦æ–‡ä»¶")
    
    print(f"ğŸ“š å·²ç´¢å¼•æ–‡ä»¶: {indexing_status['indexed_files_count']:,}")
    print(f"ğŸ’¾ å‘é‡æ•¸æ“šåº«å¤§å°: {get_file_size_str(indexing_status['vector_db_size'])}")
    print(f"ğŸ“ æ—¥èªŒæ–‡ä»¶å¤§å°: {get_file_size_str(indexing_status['log_file_size'])}")
    
    # é¡¯ç¤ºç³»çµ±ç‹€æ…‹
    print("\nğŸ–¥ï¸  ç³»çµ±ç‹€æ…‹:")
    print("-" * 40)
    
    memory_icon = "ğŸ”´" if system_status['memory_percent'] > 85 else "ğŸŸ¡" if system_status['memory_percent'] > 70 else "ğŸŸ¢"
    disk_icon = "ğŸ”´" if system_status['disk_percent'] > 90 else "ğŸŸ¡" if system_status['disk_percent'] > 80 else "ğŸŸ¢"
    q_drive_icon = "ğŸŸ¢" if system_status['q_drive_accessible'] else "ğŸ”´"
    ollama_icon = "ğŸŸ¢" if system_status['ollama_running'] else "ğŸ”´"
    
    print(f"{memory_icon} å…§å­˜ä½¿ç”¨: {system_status['memory_percent']:.1f}%")
    print(f"{disk_icon} ç£ç›¤ä½¿ç”¨: {system_status['disk_percent']:.1f}%")
    print(f"{q_drive_icon} Qæ§½è¨ªå•: {'æ­£å¸¸' if system_status['q_drive_accessible'] else 'ç•°å¸¸'}")
    print(f"{ollama_icon} Ollamaæœå‹™: {'é‹è¡Œä¸­' if system_status['ollama_running'] else 'åœæ­¢'}")
    
    # é¡¯ç¤ºæœ€è¿‘æ—¥èªŒ
    if indexing_status['last_log_lines']:
        print("\nğŸ“‹ æœ€è¿‘æ—¥èªŒ (æœ€å¾Œ10è¡Œ):")
        print("-" * 40)
        for line in indexing_status['last_log_lines']:
            if line:
                # ç°¡åŒ–æ—¥èªŒé¡¯ç¤º
                if len(line) > 100:
                    line = line[:97] + "..."
                print(f"  {line}")
    
    print("\n" + "=" * 80)
    print("æŒ‰ Ctrl+C é€€å‡ºç›£æ§")

def monitor_loop(interval=5):
    """ç›£æ§å¾ªç’°"""
    try:
        while True:
            display_status()
            time.sleep(interval)
    except KeyboardInterrupt:
        print("\n\nç›£æ§å·²åœæ­¢")

def show_detailed_progress():
    """é¡¯ç¤ºè©³ç´°é€²åº¦"""
    from config.config import VECTOR_DB_PATH
    
    progress_file = Path(VECTOR_DB_PATH) / "indexing_progress.json"
    if not progress_file.exists():
        print("âŒ æœªæ‰¾åˆ°é€²åº¦æ–‡ä»¶")
        return
    
    try:
        with open(progress_file, 'r', encoding='utf-8') as f:
            progress = json.load(f)
        
        print("ğŸ“Š è©³ç´°ç´¢å¼•é€²åº¦:")
        print("-" * 50)
        print(f"é€²è¡Œä¸­: {progress.get('in_progress', False)}")
        print(f"å·²å®Œæˆæ‰¹æ¬¡: {progress.get('completed_batches', 0)}")
        print(f"ç¸½æ‰¹æ¬¡æ•¸: {progress.get('total_batches', 0)}")
        print(f"å¾…è™•ç†æ–‡ä»¶æ•¸: {len(progress.get('pending_files', []))}")
        print(f"ç•¶å‰æ‰¹æ¬¡æ–‡ä»¶æ•¸: {len(progress.get('current_batch', []))}")
        
        # é¡¯ç¤ºä¸€äº›å¾…è™•ç†æ–‡ä»¶ç¤ºä¾‹
        pending_files = progress.get('pending_files', [])
        if pending_files:
            print(f"\nğŸ“„ å¾…è™•ç†æ–‡ä»¶ç¤ºä¾‹ (å‰10å€‹):")
            for i, file_path in enumerate(pending_files[:10]):
                print(f"  {i+1}. {file_path}")
            if len(pending_files) > 10:
                print(f"  ... é‚„æœ‰ {len(pending_files) - 10} å€‹æ–‡ä»¶")
        
    except Exception as e:
        print(f"âŒ è®€å–é€²åº¦æ–‡ä»¶å¤±æ•—: {str(e)}")

def reset_progress():
    """é‡ç½®é€²åº¦"""
    from config.config import VECTOR_DB_PATH
    
    progress_file = Path(VECTOR_DB_PATH) / "indexing_progress.json"
    
    confirm = input("âš ï¸  ç¢ºå®šè¦é‡ç½®ç´¢å¼•é€²åº¦å—ï¼Ÿé€™å°‡æ¸…é™¤æ‰€æœ‰é€²åº¦è¨˜éŒ„ (y/N): ")
    if confirm.lower() != 'y':
        print("æ“ä½œå·²å–æ¶ˆ")
        return
    
    try:
        reset_progress_data = {
            "pending_files": [],
            "current_batch": [],
            "completed_batches": 0,
            "total_batches": 0,
            "in_progress": False
        }
        
        with open(progress_file, 'w', encoding='utf-8') as f:
            json.dump(reset_progress_data, f, ensure_ascii=False, indent=2)
        
        print("âœ… ç´¢å¼•é€²åº¦å·²é‡ç½®")
        
    except Exception as e:
        print(f"âŒ é‡ç½®é€²åº¦å¤±æ•—: {str(e)}")

def get_status_text(model_folder_name: Optional[str] = None):
    from io import StringIO
    import sys as _sys
    buf = StringIO()
    _stdout = _sys.stdout
    _sys.stdout = buf
    try:
        display_status(model_folder_name)
    finally:
        _sys.stdout = _stdout
    return buf.getvalue()

def get_progress_text(model_folder_name: Optional[str] = None):
    from io import StringIO
    import sys as _sys
    buf = StringIO()
    _stdout = _sys.stdout
    _sys.stdout = buf
    try:
        # Note: show_detailed_progress is not yet adapted for model_folder_name
        # It will need similar logic to get_indexing_status if used.
        # For now, it might report global state.
        show_detailed_progress()
    finally:
        _sys.stdout = _stdout
    return buf.getvalue()

def get_monitor_text(model_folder_name: Optional[str] = None, interval=5, once=False):
    from io import StringIO
    import sys as _sys
    import time as _time
    buf = StringIO()
    _stdout = _sys.stdout
    _sys.stdout = buf
    try:
        if once:
            display_status(model_folder_name)
        else:
            try:
                while True:
                    display_status(model_folder_name)
                    _time.sleep(interval)
            except KeyboardInterrupt:
                print("\n\nç›£æ§å·²åœæ­¢")
    finally:
        _sys.stdout = _stdout
    return buf.getvalue()


def main():
    parser = argparse.ArgumentParser(description="ç´¢å¼•ç›£æ§å·¥å…·")
    parser.add_argument('--monitor', '-m', action='store_true', help='å•Ÿå‹•å¯¦æ™‚ç›£æ§')
    parser.add_argument('--status', '-s', action='store_true', help='é¡¯ç¤ºç•¶å‰ç‹€æ…‹')
    parser.add_argument('--progress', '-p', action='store_true', help='é¡¯ç¤ºè©³ç´°é€²åº¦')
    parser.add_argument('--reset', '-r', action='store_true', help='é‡ç½®é€²åº¦')
    parser.add_argument('--interval', '-i', type=int, default=5, help='ç›£æ§åˆ·æ–°é–“éš”(ç§’)')
    
    args = parser.parse_args()
    
    if args.monitor:
        monitor_loop(args.interval)
    elif args.status:
        display_status()
        input("\næŒ‰ Enter éµé€€å‡º...")
    elif args.progress:
        show_detailed_progress()
    elif args.reset:
        reset_progress()
    else:
        # é»˜èªé¡¯ç¤ºç‹€æ…‹
        display_status()
        input("\næŒ‰ Enter éµé€€å‡º...")

if __name__ == "__main__":
    main()