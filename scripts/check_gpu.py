#!/usr/bin/env python3
"""
æª¢æŸ¥ GPU å¯ç”¨æ€§
"""

import sys
import os

def check_pytorch_gpu():
    """æª¢æŸ¥ PyTorch GPU æ”¯æ´"""
    print("ğŸ” æª¢æŸ¥ PyTorch GPU æ”¯æ´...")
    
    try:
        import torch
        print(f"âœ… PyTorch ç‰ˆæœ¬: {torch.__version__}")
        
        # æª¢æŸ¥ CUDA å¯ç”¨æ€§
        cuda_available = torch.cuda.is_available()
        print(f"CUDA å¯ç”¨: {'âœ… æ˜¯' if cuda_available else 'âŒ å¦'}")
        
        if cuda_available:
            # GPU è©³ç´°ä¿¡æ¯
            gpu_count = torch.cuda.device_count()
            print(f"GPU æ•¸é‡: {gpu_count}")
            
            for i in range(gpu_count):
                gpu_name = torch.cuda.get_device_name(i)
                gpu_props = torch.cuda.get_device_properties(i)
                memory_gb = gpu_props.total_memory / 1e9
                print(f"  GPU {i}: {gpu_name} ({memory_gb:.1f}GB)")
            
            # ç•¶å‰è¨­å‚™
            current_device = torch.cuda.current_device()
            print(f"ç•¶å‰è¨­å‚™: GPU {current_device}")
            
            # CUDNN ç‰ˆæœ¬
            if torch.backends.cudnn.is_available():
                cudnn_version = torch.backends.cudnn.version()
                print(f"CUDNN ç‰ˆæœ¬: {cudnn_version}")
            else:
                print("CUDNN: âŒ ä¸å¯ç”¨")
        else:
            print("åŸå› å¯èƒ½:")
            print("  - æ²’æœ‰å®‰è£ NVIDIA GPU")
            print("  - æ²’æœ‰å®‰è£ CUDA")
            print("  - PyTorch æ˜¯ CPU ç‰ˆæœ¬")
            print("  - GPU é©…å‹•å•é¡Œ")
        
        return cuda_available
        
    except ImportError:
        print("âŒ PyTorch æœªå®‰è£")
        return False
    except Exception as e:
        print(f"âŒ æª¢æŸ¥å¤±æ•—: {e}")
        return False

def check_system_gpu():
    """æª¢æŸ¥ç³»çµ± GPU"""
    print("\nğŸ” æª¢æŸ¥ç³»çµ± GPU...")
    
    try:
        # Windows
        if os.name == 'nt':
            import subprocess
            result = subprocess.run(['wmic', 'path', 'win32_VideoController', 'get', 'name'], 
                                  capture_output=True, text=True)
            if result.returncode == 0:
                lines = result.stdout.strip().split('\n')
                gpus = [line.strip() for line in lines[1:] if line.strip()]
                if gpus:
                    print("ç³»çµ±æª¢æ¸¬åˆ°çš„ GPU:")
                    for gpu in gpus:
                        print(f"  - {gpu}")
                        if "NVIDIA" in gpu.upper():
                            print("    âœ… NVIDIA GPU æª¢æ¸¬åˆ°")
                        elif "AMD" in gpu.upper() or "RADEON" in gpu.upper():
                            print("    âš ï¸ AMD GPU (PyTorch ä¸»è¦æ”¯æ´ NVIDIA)")
                        elif "INTEL" in gpu.upper():
                            print("    âš ï¸ Intel é›†æˆé¡¯å¡ (ä¸é©åˆæ·±åº¦å­¸ç¿’)")
                else:
                    print("âŒ æ²’æœ‰æª¢æ¸¬åˆ° GPU")
            else:
                print("âŒ ç„¡æ³•æª¢æ¸¬ç³»çµ± GPU")
        else:
            # Linux/Mac
            try:
                result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
                if result.returncode == 0:
                    print("âœ… NVIDIA GPU æª¢æ¸¬åˆ°:")
                    print(result.stdout)
                else:
                    print("âŒ nvidia-smi å‘½ä»¤å¤±æ•—ï¼Œå¯èƒ½æ²’æœ‰ NVIDIA GPU æˆ–é©…å‹•")
            except FileNotFoundError:
                print("âŒ nvidia-smi å‘½ä»¤ä¸å­˜åœ¨")
                
    except Exception as e:
        print(f"âŒ ç³»çµ± GPU æª¢æŸ¥å¤±æ•—: {e}")

def check_environment_config():
    """æª¢æŸ¥ç’°å¢ƒé…ç½®"""
    print("\nğŸ” æª¢æŸ¥ç’°å¢ƒé…ç½®...")
    
    # æ·»åŠ é …ç›®è·¯å¾‘
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    
    try:
        from config.config import TORCH_DEVICE, HF_USE_GPU
        
        print(f"TORCH_DEVICE: {TORCH_DEVICE}")
        print(f"HF_USE_GPU: {HF_USE_GPU}")
        
        if TORCH_DEVICE == "auto":
            print("âœ… è¨­å‚™è¨­ç½®ç‚ºè‡ªå‹•æª¢æ¸¬")
        elif TORCH_DEVICE == "cpu":
            print("âš ï¸ å¼·åˆ¶ä½¿ç”¨ CPU")
        elif TORCH_DEVICE == "cuda":
            print("âš ï¸ å¼·åˆ¶ä½¿ç”¨ CUDA")
        
        if not HF_USE_GPU:
            print("âš ï¸ HF_USE_GPU è¨­ç½®ç‚º Falseï¼Œå°‡ä¸ä½¿ç”¨ GPU")
            
    except Exception as e:
        print(f"âŒ é…ç½®æª¢æŸ¥å¤±æ•—: {e}")

def check_cuda_installation():
    """æª¢æŸ¥ CUDA å®‰è£"""
    print("\nğŸ” æª¢æŸ¥ CUDA å®‰è£...")
    
    try:
        # æª¢æŸ¥ CUDA ç’°å¢ƒè®Šæ•¸
        cuda_path = os.environ.get('CUDA_PATH')
        if cuda_path:
            print(f"CUDA_PATH: {cuda_path}")
        else:
            print("âŒ CUDA_PATH ç’°å¢ƒè®Šæ•¸æœªè¨­ç½®")
        
        # æª¢æŸ¥ nvcc
        import subprocess
        try:
            result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)
            if result.returncode == 0:
                print("âœ… NVCC å¯ç”¨:")
                print(result.stdout.strip())
            else:
                print("âŒ NVCC ä¸å¯ç”¨")
        except FileNotFoundError:
            print("âŒ NVCC å‘½ä»¤ä¸å­˜åœ¨")
            
    except Exception as e:
        print(f"âŒ CUDA æª¢æŸ¥å¤±æ•—: {e}")

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ GPU å¯ç”¨æ€§æª¢æŸ¥")
    print("=" * 50)
    
    # æª¢æŸ¥ç³»çµ± GPU
    check_system_gpu()
    
    # æª¢æŸ¥ CUDA å®‰è£
    check_cuda_installation()
    
    # æª¢æŸ¥ PyTorch GPU æ”¯æ´
    pytorch_gpu = check_pytorch_gpu()
    
    # æª¢æŸ¥ç’°å¢ƒé…ç½®
    check_environment_config()
    
    # ç¸½çµ
    print("\n" + "=" * 50)
    print("ğŸ“Š ç¸½çµ:")
    
    if pytorch_gpu:
        print("âœ… GPU å¯ç”¨ï¼Œç³»çµ±å°‡è‡ªå‹•ä½¿ç”¨ GPU åŠ é€Ÿ")
        print("ğŸ’¡ å»ºè­°:")
        print("  - å¯ä»¥ä½¿ç”¨ vLLM æ¨ç†å¼•æ“ç²å¾—æ›´å¥½æ€§èƒ½")
        print("  - å¯ä»¥è¼‰å…¥æ›´å¤§çš„æ¨¡å‹")
    else:
        print("âŒ GPU ä¸å¯ç”¨ï¼Œç³»çµ±å°‡ä½¿ç”¨ CPU")
        print("ğŸ’¡ å»ºè­°:")
        print("  - ä½¿ç”¨è¼ƒå°çš„æ¨¡å‹ï¼ˆå¦‚ Qwen2 0.5Bï¼‰")
        print("  - ä½¿ç”¨ Transformers æ¨ç†å¼•æ“")
        print("  - å¦‚æœéœ€è¦ GPUï¼Œè«‹å®‰è£ CUDA å’Œ GPU ç‰ˆæœ¬çš„ PyTorch")

if __name__ == "__main__":
    main()